
# static pages

from django.shortcuts import render

def contact(request):
    return render(request, "contact.html")

def main(request):
    return render(request, "main.html")

def about(request):
    return render(request, "about.html")

# bert-base: This indicates that the model is based on the BERT architecture, which is a transformer-based model. 
# The "base" typically refers to the smaller version of BERT (as opposed to "large" or other variants), and it has a base vocabulary size.

# nli: This refers to Natural Language Inference, which is a type of task where the model is trained to determine the 
# logical relationship between pairs of sentences. The classes usually include "entailment" (one sentence logically follows from another), 
# "contradiction" (one sentence contradicts the other), and "neutral" (there is no logical relationship).

# mean-tokens: This part indicates that, during the inference phase, the sentence embeddings are generated by taking the mean 
# (average) of the individual token embeddings within the sentence. This process results in a fixed-size vector representation 
# for variable-length sentences.

# So, when you use the "bert-base-nli-mean-tokens" pre-trained model, it is expected to be proficient in tasks related to Natural 
#     Language Inference, and it generates sentence embeddings by considering the mean of token embeddings. This model could be useful 
# for tasks such as sentence similarity, where you want to compare the semantic similarity between different sentences.


# Exactly, you've captured the key distinction. In Natural Language Inference (NLI) tasks, the focus is on understanding the logical
# relationships between sentences. The model is trained to discern whether one sentence logically entails, contradicts, or is neutral
# to another. This requires a deeper understanding of the semantics and meaning of the text.

# Contrastingly, models like TF-IDF (Term Frequency-Inverse Document Frequency) primarily work based on the statistical importance 
# of words in a document or a corpus. They don't inherently capture the semantic relationships between words or sentences. TF-IDF is
# often used for tasks like document retrieval, where the goal is to find documents that contain specific keywords.

# sentence transformer provides an abstract layer that applies all the steps of the bert-nli-mean-token at once


# functions for backend
from django.http import HttpResponse
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import os
import time, uuid
import threading
from datetime import datetime
import sqlite3


BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

STATIC_URL = '/static/'

# For development
STATICFILES_DIRS = [os.path.join(BASE_DIR, 'Law_Assistant', 'static')]
dataset_path = os.path.join(BASE_DIR, 'Law_Assistant', 'static', 'database', 'fyp_data.db')
contact_path = os.path.join(BASE_DIR, 'Law_Assistant', 'static', 'database', 'contact.db')

target_column = "Generated scenario"
model_updating = False

def load_model():
    model = SentenceTransformer('bert-base-nli-mean-tokens')
    return model

def load_embeddings():
    print("init dataset")
    conn = sqlite3.connect(dataset_path)
    query = "SELECT * FROM fyp_data"
    dataset = pd.read_sql_query(query, conn)
    X =  dataset['Reverse engineering question'].astype(str) + ' ' + dataset[target_column].astype(str) + ' ' + dataset['Additional User Question'].astype(str)
    model = load_model()
    print("init model")
    train_similar_embeddings = X.apply(lambda x: model.encode(str(x)))
    train_dissimilar_embeddings = dataset['restricted user questions'].apply(lambda x: model.encode(str(x)))
    start_time = time.time()
    print("init model done")
    return dataset, model, train_similar_embeddings, train_dissimilar_embeddings, start_time

def update_model():
    while True:
        current_time = datetime.now()
        print(f'constantly checkig for updates, current hour is: {current_time.hour}')
        if current_time.hour % 4 == 0:
            print("Updating model...")
            load_embeddings()
            time.sleep(30 * 60)
        threading.Event().wait(30)

def update_dataset_yes(dataset_path, matched_scenario, additional_user_question):
    conn = sqlite3.connect(dataset_path)
    cursor = conn.cursor()

    # Query to update the 'Additional User Question' column based on 'Subsectionlist'
    update_query = """
    UPDATE fyp_data
    SET 'Additional User Question' = ? 
    WHERE Subsectionlist = ?
    """

    # Execute the query with parameters
    cursor.execute(update_query, (additional_user_question, matched_scenario))

    conn.commit()
    conn.close()

def update_dataset_no(dataset_path, matched_scenario, additional_user_question):
    conn = sqlite3.connect(dataset_path)
    cursor = conn.cursor()

    # Query to update the 'Additional User Question' column based on 'Subsectionlist'
    update_query = """
    UPDATE fyp_data
    SET 'restricted user questions' = ? 
    WHERE Subsectionlist = ?
    """

    # Execute the query with parameters
    cursor.execute(update_query, (additional_user_question, matched_scenario))

    conn.commit()
    conn.close()


def save_to_db(name, email, query, contact_path):
    conn = sqlite3.connect(contact_path)
    cursor = conn.cursor()

    cursor.execute(f"INSERT INTO contacts (Name, Email, Query) VALUES (?, ?, ?)", (name, email, query))

    conn.commit()
    conn.close()

def process_form(request):
    if request.method == 'POST':
        print("Contact submit")
        name = request.POST.get('name')
        email = request.POST.get('email')
        query = request.POST.get('query')
        save_to_db(name, email, query, contact_path)

        # Assuming you have a contact.html template in the templates folder
        return render(request, "contact.html", {'sent': True} )

    # Handle GET request or other methods
    return HttpResponse("Method Not Allowed", status=405)


# links for action


def feedback(request):
    if request.method == 'POST':
        user_feedback = request.POST.get('feed', '').lower()
        if user_feedback.lower() == "no":
            most_similar_info = request.session['most_similar_info']
            additional_user_questions = most_similar_info['restricted user questions']
            additional_user_questions = f"{additional_user_questions}\n{request.session['user_scenario']}"
            subsection_list = most_similar_info.get('Subsectionlist', '')

            update_dataset_no(dataset_path, subsection_list, additional_user_questions)

            p = request.session.get('p') + 1
            request.session['p'] = p

            sorted_indices = sorted(enumerate(request.session['dfc']), key=lambda x: x[1], reverse=True)
            if request.session['p'] < len(sorted_indices):
                selected_index = sorted_indices[request.session['p']][0]
                most_similar_info = dataset.loc[selected_index].to_dict()
                print(f"sent prediction {request.session['p']}")
                request.session['most_similar_info'] = most_similar_info
            return render(request, 'chat.html', {
                'relevant_act': most_similar_info['Relevant act/ordinance Apply'],
                'user_question': request.session['user_scenario'],
                'relevant_section': most_similar_info['Relevant section  of Act Apply if any'],
                'Subsectionlist': most_similar_info['Subsectionlist'],
                'feedback_return': "Thank you for your feedback! I am still in the development phase. Was that helpful?",
                'input': "Null"
            })

        elif user_feedback.lower() == "yes":
            most_similar_info = request.session['most_similar_info']
            additional_user_questions = most_similar_info['Additional User Question']
            additional_user_questions = f"{additional_user_questions}\n{request.session['user_scenario']}"
            subsection_list = most_similar_info.get('Subsectionlist', '')
            update_dataset_yes(dataset_path, subsection_list, additional_user_questions)
            print(f"sent prediction {request.session.get('p') + 1}")

            return render(request, 'chat.html', {
                'relevant_act': most_similar_info['Relevant act/ordinance Apply'],
                'user_question': request.session['user_scenario'],
                'relevant_section': most_similar_info['Relevant section  of Act Apply if any'],
                'Subsectionlist': most_similar_info['Subsectionlist'],
                'feedback_return': "Thank you for your feedback! This will help the model improve automatically.",
                'input': ""
            })

    # Handle GET request or other methods
    return HttpResponse("Method Not Allowed", status=405)


def predict(request):
    if request.method == 'POST':
        print("got user scenario")
        user_scenario = request.POST['user_scenario']
        request.session['user_scenario'] = user_scenario
        user_scenario = request.session['user_scenario']
        user_embedding = model.encode(request.session['user_scenario'])
        dfs = train_similar_embeddings.apply(lambda x: util.pytorch_cos_sim(user_embedding, x).item())
        dfd = train_dissimilar_embeddings.apply(lambda x: util.pytorch_cos_sim(user_embedding, x).item())
        dfc = dfs - dfd
        request.session['dfc'] = dfc.tolist()
        p = 0
        print(f'p at start: {p}')
        request.session['p'] = p
        max_value = max(request.session['dfc'])
        max_index = request.session['dfc'].index(max_value)
        most_similar_info = dataset.loc[max_index].to_dict() 
        print(f"sent prediction {request.session['p']}")
        request.session['most_similar_info'] = most_similar_info
        return render(request, 'chat.html', {
            'relevant_act': most_similar_info['Relevant act/ordinance Apply'],
            'user_question': request.session['user_scenario'],
            'relevant_section': most_similar_info['Relevant section  of Act Apply if any'],
            'Subsectionlist': most_similar_info['Subsectionlist'],
            'feedback_return': "Was That Helpful?",
            'input': "Null"
        })

print("Program started")
global dataset, model, train_similar_embeddings, train_dissimilar_embeddings, start_time 
dataset, model, train_similar_embeddings, train_dissimilar_embeddings, start_time = load_embeddings()
print("starting updation thread")
model_thread = threading.Thread(target=update_model)
model_thread.start()
print("Program done")


def chat(request):
    if 'user_id' not in request.session:
        user_id = str(uuid.uuid4())
        request.session['user_id'] = user_id
    return render(request, "chat.html")
